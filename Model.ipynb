{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks for Decentralized Multi-Robot Path Planning In Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset_Generator import DatasetGenerator \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [[0 for _ in range(20)] for _ in range(20)]  # Generate grid map\n",
    "dataset_generator = DatasetGenerator(num_cases=5000, num_agents=10, grid=grid)\n",
    "cases = dataset_generator.generate_cases()\n",
    "# dataset_generator.save_cases_to_file(cases, \"dataset.json\")\n",
    "# print(f\"Generated and saved {len(cases)} cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processing import Preprocessing\n",
    "p = Preprocessing(grid,cases,3)\n",
    "data_tensors  = p.begin()\n",
    "with open(\"data_tensors.txt\", 'w') as file:\n",
    "    file.write(str(data_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentages:  0.9943489490147263\n",
      "Number of non optiaml paths:  2225\n",
      "Percentage of non optimal paths to the all paths:  0.037083333333333336\n"
     ]
    }
   ],
   "source": [
    "from Mo_Star import MoStar\n",
    "from Dataset_Generator import DatasetGenerator\n",
    "import numpy as np\n",
    "grid = [[0 for _ in range(20)] for _ in range(20)] #generate grid map\n",
    "\n",
    "dataset_generator = DatasetGenerator(5000,10,grid)\n",
    "loaded_cases = dataset_generator.load_cases_from_file(\"dataset.json\")\n",
    "import networkx as nx\n",
    "\n",
    "rows, cols = 20, 20\n",
    "G = nx.grid_2d_graph(rows, cols)\n",
    "\n",
    "percentages = []\n",
    "\n",
    "for i in range(len(loaded_cases)):\n",
    "    for j in range(len(loaded_cases[0][\"start_positions\"])):\n",
    "        start = loaded_cases[i][\"start_positions\"][j]\n",
    "        goal = loaded_cases[i][\"goal_positions\"][j]\n",
    "        path = loaded_cases[i][\"paths\"][j]\n",
    "        shortest_path = nx.shortest_path(G, source=(start[0],start[1]), target=(goal[0],goal[1]))\n",
    "        percentages.append([len(shortest_path)/len(path)])\n",
    "num_of_not_optimal_paths = 0\n",
    "\n",
    "for i in range(len(percentages)):\n",
    "    if percentages[i][0] != 1.0:\n",
    "        num_of_not_optimal_paths+=1\n",
    "avg_percentage = np.sum(percentages)/len(percentages)\n",
    "print(\"Average percentages: \",avg_percentage)\n",
    "print(\"Number of non optiaml paths: \", num_of_not_optimal_paths)\n",
    "print(\"Percentage of non optimal paths to the all paths: \", num_of_not_optimal_paths/len(percentages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "num_of_confilicts = 0\n",
    "list_of_confilicts = []\n",
    "i = 0\n",
    "for case in loaded_cases:\n",
    "    max_len = max(case[\"paths\"])\n",
    "    for step in range(len(max_len)):\n",
    "        step_nodes = {}\n",
    "        for path in case[\"paths\"]:\n",
    "            if step < len(path):\n",
    "                if (path[step][0],path[step][1],step) in step_nodes:\n",
    "                    num_of_confilicts+=1\n",
    "                    list_of_confilicts.append((path[step][0],path[step][1],step,i))\n",
    "                else:\n",
    "                    step_nodes[(path[step][0],path[step][1],step)] = 1 \n",
    "            else:\n",
    "                if (path[-1][0],path[-1][1],step) in step_nodes:\n",
    "                    num_of_confilicts+=1\n",
    "                    list_of_confilicts.append((path[-1][0],path[-1][1],step,i))\n",
    "                else:\n",
    "                    step_nodes[(path[-1][0],path[-1][1],step)] = 1\n",
    "        step_nodes.clear()\n",
    "    i+=1\n",
    "print(num_of_confilicts)\n",
    "print(list_of_confilicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
